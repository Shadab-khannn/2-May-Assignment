{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfba222-929f-4033-ad05-d87ccd6730e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is anomaly detection and what is its purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799dfb6a-cecf-4c15-8841-565eaf20fdea",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38688658-e600-45e3-973c-d215bcd6ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anomaly detection is the identification of rare events, items, or observations that deviate from normal behavior or patterns in data.\n",
    "It is a process in machine learning that is critical for industrial applications like predictive and prescriptive maintenance.\n",
    "Anomaly detection can be done using the concepts of Machine Learning. \n",
    "It can be done in the following ways – Supervised Anomaly Detection: This method requires a labeled dataset containing both normal and \n",
    "anomalous samples to construct a predictive model to classify future data points.\n",
    "\n",
    "The purpose of anomaly detection is to identify unusual patterns that do not conform to expected behavior. \n",
    "It is used in various fields such as fraud detection, intrusion detection, fault detection, system health monitoring,\n",
    "event detection in sensor networks, and detecting ecosystem disturbances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979ac77-3999-430c-8ceb-ff20a0c00b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b9767-6a3e-48c7-a0c4-76262d85585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the key challenges in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9af65ae-1139-455d-b6a3-86a066eab8af",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1d854-0af7-4df5-bbfa-62ad2b8872f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Some common challenges and pitfalls of anomaly detection are:\n",
    "\n",
    "1.The rarity, heterogeneity, and boundless nature of anomalies make it difficult to apply popular deep learning techniques.\n",
    "2.The lack of large-scale labeled anomaly data limits the expressiveness and generalization of detection models.\n",
    "3.The need to define the problem clearly, choose the right algorithm, validate and tune the algorithm,\n",
    "  and deploy and monitor the algorithm in real-world scenarios.\n",
    "    \n",
    "Other challenges include modeling normal behavior to provide the correct context, separating noise a major obstacle in identifying real \n",
    "outliers, extracting useful features appropriately3, defining what is considered “normal,” and dealing with the situations where there \n",
    "are significantly more normal values than anomalies.\n",
    "Difficulties brought by anomaly detection can be brought on by both high dimensionality and the enormous amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826b096-3ba5-4c22-8b8c-631ac1104d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13f875-15c9-4aaf-b7f3-6d7a26f4e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304b74a-8010-4932-b918-68c89026171d",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a39e9-84de-4859-a78d-00377e985ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unsupervised anomaly detection is the process of identifying unexpected items or events in unlabeled datasets, which differ from the norm.\n",
    "It does not require any prior knowledge about the anomalies, but assumes that they are rare and make up a small percentage of the data.\n",
    "It involves modeling the normal data distribution and defining a measurement to classify samples as anomalous or normal.\n",
    "\n",
    "Supervised anomaly detection requires labeled data that indicates if a record is normal or abnormal.\n",
    "The main difference between supervised and unsupervised anomaly detection is the approach involved, where supervised approach makes use of\n",
    "predefined algorithms and AI training, while unsupervised approach uses a general outlier-detection mechanism based on pattern matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914fa811-b306-40b8-b24f-765963236726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b65194-b04b-4d54-b740-c90a4b2d73d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are the main categories of anomaly detection algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49742d-089b-4331-9db1-bc39678aeff1",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae63329-3934-41d1-a7cf-c46e10961252",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anomaly detection algorithms can be broadly categorized into three categories:\n",
    "\n",
    "1.Statistical methods\n",
    "2.Machine learning methods\n",
    "3.Hybrid methods.\n",
    "\n",
    "Statistical methods include Z-score, modified Z-score, and percentile-based methods. \n",
    "Machine learning methods include clustering-based methods, classification-based methods, and density-based methods. \n",
    "Hybrid methods combine statistical and machine learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea354d3d-a757-4ebb-9a15-dba50d863b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a29602-97f9-4d84-9bff-fc62e6327c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba7e43-fe14-46ec-9d9d-dfa43c629a98",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e92e4e-1e65-4731-873f-79a5464025f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance-based anomaly detection methods assume that normal data points are clustered together while anomalies are far away\n",
    "from the normal data points.\n",
    "These methods use distance measures such as Euclidean distance, Mahalanobis distance, and cosine similarity to identify anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904956a-b568-4d49-a3b0-afc0d0ef87ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa774ff9-5911-41fe-b8b5-8b73e79d6203",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. How does the LOF algorithm compute anomaly scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a88536f-1559-41a9-ad0e-194c74b59afa",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65093955-9176-43b5-8533-b668fe165c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "The LOF (Local Outlier Factor) algorithm computes anomaly scores by comparing the density of a data point with the densities of its \n",
    "k-nearest neighbors. \n",
    "The anomaly score is the ratio of the average local reachability density of the k-nearest neighbors to the local reachability density \n",
    "of the data point itself.\n",
    "\n",
    "Received message. The LOF (Local Outlier Factor) algorithm computes anomaly scores by comparing the density of a data point with the\n",
    "densities of its k-nearest neighbors. \n",
    "The anomaly score is the ratio of the average local reachability density of the k-nearest neighbors to the local reachability density \n",
    "of the data point itself.\n",
    "\n",
    "The local reachability density of a data point is the inverse of the average reachability distance of its k-nearest neighbors. \n",
    "The reachability distance is the maximum of the distance between two data points and the k-th nearest neighbor distance of the \n",
    "second data point. The local reachability density measures how dense the region around a data point is compared to its neighbors.\n",
    "\n",
    "Received message. The local reachability density of a data point is the inverse of the average reachability distance of its k-nearest \n",
    "neighbors. \n",
    "The reachability distance is the maximum of the distance between two data points and the k-th nearest neighbor distance of the \n",
    "second data point. The local reachability density measures how dense the region around a data point is compared to its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc57f6-cf34-40e4-a8da-e4c7ddfa4884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd99d26-7962-4c75-a8f6-770752791515",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What are the key parameters of the Isolation Forest algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62926976-9c5e-45ae-a8ae-4724902d4187",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a5a6e-3dc7-4b71-aa9e-9e7f7c8f4ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Isolation Forest algorithm is an unsupervised learning algorithm that identifies anomalies by isolating them in the data space.\n",
    "The algorithm works by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of\n",
    "the selected feature.\n",
    "This process is repeated recursively until all data points are isolated or the isolation tree reaches a maximum depth.\n",
    "\n",
    "The key parameters of the Isolation Forest algorithm are:\n",
    "\n",
    "1.n_estimators: The number of trees in the forest. Increasing the number of trees improves the performance of the algorithm but also increases\n",
    "                the computational cost.\n",
    "    \n",
    "2.max_samples: The number of samples to draw from the dataset to train each tree. Increasing the number of samples improves the performance\n",
    "               of the algorithm but also increases the computational cost.\n",
    "    \n",
    "3.contamination: The proportion of anomalies in the dataset. This parameter is used to set the threshold for identifying anomalies.\n",
    "\n",
    "4.max_features: The maximum number of features to consider when splitting a node. Increasing this parameter improves the performance of the\n",
    "                algorithm but also increases the computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b7bc87-86fe-4353-a748-20ec165133dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d37c42-1f7a-43e8-b771-580d6564b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score\n",
    "using KNN with K=10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240faa8-5275-4b4d-8773-9b32919bf73f",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9edac2-d56c-4f70-8214-694c54d0f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "The anomaly score of a data point using KNN with K=10 is calculated as follows:\n",
    "\n",
    "Compute the distance between the data point and its 10th nearest neighbor.\n",
    "Compute the average distance between the data point and its 10 nearest neighbors.\n",
    "Compute the local reachability density of the data point as the inverse of the average distance.\n",
    "Compute the LOF of the data point as the ratio of the local reachability density of the data point to the local reachability densities of \n",
    "its 10 nearest neighbors.\n",
    "In this case, since there are only 2 neighbors within a radius of 0.5, it is not possible to compute an anomaly score using KNN with K=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b762b2a-8a0b-4650-91c0-2311fa385566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b46916-3d6d-4d03-a625-c27694c89b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the\n",
    "anomaly score for a data point that has an average path length of 5.0 compared to the average path\n",
    "length of the trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f66e0-4cff-4bad-af20-a4eddfd8ea2c",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde45713-ac83-41a1-be54-e162e06397bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "The anomaly score of a data point using the Isolation Forest algorithm is calculated as follows:\n",
    "\n",
    "Compute the average path length of the data point across all trees in the forest.\n",
    "Compute the anomaly score as 2^(-average path length / c), where c is a normalization factor.\n",
    "\n",
    "In this case, if a data point has an average path length of 5.0 compared to the average path length of the trees, we can calculate its \n",
    "anomaly score as follows:\n",
    "\n",
    "The average path length of the data point across all trees is 5.0.\n",
    "The normalization factor c for a dataset of 3000 data points and 100 trees is approximately 11.5 (c = 2 * (log(3000-1) + 0.5772156649)).\n",
    "The anomaly score for the data point is 2^(-5.0 / 11.5) = 0.383."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
